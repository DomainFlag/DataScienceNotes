{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding for wine reviews and sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "    \n",
    "sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import helper as hlp\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor as DecisionTreeRegressor\n",
    "\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "raw = pd.read_csv(\"./data/wine_reviews.csv\", low_memory = False);\n",
    "\n",
    "# dropping unnecessary column\n",
    "raw = raw.drop(columns = [\"Unnamed: 0\"], inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform non-numerical data to categorical\n",
    "hlp.trans_categorical(raw, labels = [\"description\"])\n",
    "\n",
    "# transform/normalize numerical data\n",
    "features, targets = hlp.trans_numerical(raw, \"points\", suffle_data_frame = True)\n",
    "\n",
    "# training and validation data\n",
    "training_set, validation_set = hlp.split_data(features, targets, threshold = 1 / 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(training_set[0][\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29871"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tdm = tfidf.fit_transform(training_set[0][\"description\"])\n",
    "\n",
    "valid_tdm = tfidf.transform(validation_set[0][\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x29871 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 60 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.transform(validation_set[0][\"description\"].iloc[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(train_tdm, training_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5484543964005837\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(validation_set[1], lr.predict(valid_tdm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_verbose(description, model, transformer, expected_score = None):\n",
    "    \n",
    "    # generate tf-idf-weighted document-term matrix\n",
    "    description_tdm = transformer.transform([description])\n",
    "\n",
    "    # predict score given description\n",
    "    score = model.predict(description_tdm)[0]\n",
    "\n",
    "    print(f\"{description:100.100}...\\\n",
    "          \\n\\t output {score}, expected {expected_score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(data, model, transformer, count = 5):\n",
    "    \n",
    "    for index in range(count):\n",
    "        \n",
    "        # current description\n",
    "        description = data[0][\"description\"][index]\n",
    "        \n",
    "        # expected output\n",
    "        score = validation_set[1][index]\n",
    "        \n",
    "        validation_verbose(description, model, transformer, expected_score = score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less effusive on the nose than the Mort's Block, this boasts notes of tangerine zest and lemon. This...          \n",
      "\t output 91, expected 92\n",
      "\n",
      "88-90 Barrel sample. Caramel new wood aromas are followed by spice and toast flavors. The fruit seem...          \n",
      "\t output 89, expected 89\n",
      "\n",
      "Somewhat smoky and earthy on the nose, but also with some harshness that could be chalked up to yout...          \n",
      "\t output 87, expected 84\n",
      "\n",
      "A product of the cool 2010 vintage, this has a green, minty flavor, with notes of lemon and lime. It...          \n",
      "\t output 87, expected 89\n",
      "\n",
      "Blended with a little Cabernet Sauvignon, this Petit Verdot succeeds wildly in appealing to the sens...          \n",
      "\t output 87, expected 92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# some input from validation set\n",
    "validation(validation_set, lr, tfidf, count = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty bad, can't handle the taste, extremely sour, how can someone make such wine?                 ...          \n",
      "\t output 82, expected None\n",
      "\n",
      "Amazing, fine vintage, delicious, rich texture that sobbing for more takes, just pure quality.      ...          \n",
      "\t output 92, expected None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# some custom input\n",
    "\n",
    "# average score\n",
    "validation_verbose(\"Pretty bad, can't handle the taste, extremely sour, how can someone make such wine?\", lr, tfidf)\n",
    "\n",
    "# good score\n",
    "validation_verbose(\"Amazing, fine vintage, delicious, rich texture that sobbing for more takes, just pure quality.\", lr, tfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
