{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from pydub import AudioSegment\n",
    "from scipy.signal import detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 4096\n",
    "\n",
    "chunk = 20\n",
    "chunk_samples_count = sampling_rate // chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magnitude extractor\n",
    "def magnitude_extractor(x, N):\n",
    "    return 20 * np.log10(np.sqrt(np.real(x) ** 2 + np.imag(x) ** 2) / chunk_samples_count + 1)\n",
    "\n",
    "def read_audio_source(file_name):\n",
    "    raw = AudioSegment.from_mp3(\"dataset\\\\xx\\\\\" + file_name)\n",
    "    raw = raw.set_channels(1)\n",
    "    raw = raw.set_frame_rate(sampling_rate)\n",
    "\n",
    "    data = raw.get_array_of_samples()\n",
    "    data = np.array(data)\n",
    "\n",
    "    chunk_count = len(data) // chunk_samples_count\n",
    "\n",
    "    data = data[:chunk_count * chunk_samples_count].reshape(-1, chunk_samples_count)\n",
    "\n",
    "    # kaiser window for reducing spectral leakage\n",
    "    window = np.kaiser(chunk_samples_count, beta = 14)\n",
    "\n",
    "    data = detrend(data, axis = 1) * window\n",
    "    \n",
    "    N = chunk_samples_count // 2\n",
    "\n",
    "    data = magnitude_extractor(np.fft.fft(data)[:, :N], 1)\n",
    "    bins = np.fft.fftfreq(chunk_samples_count, 1 / sampling_rate)[:N]\n",
    "    \n",
    "    return (data, bins)\n",
    "    \n",
    "def chunk_plot(x_input, y_input):\n",
    "    fig = plt.figure(figsize = (25, 4))\n",
    "    \n",
    "    for index, input in enumerate(y_input):\n",
    "        ax = fig.add_subplot(1, 6, index + 1)\n",
    "        ax.plot(x_input, input)\n",
    "        ax.set_xlabel('Frequency (kHz)')\n",
    "        ax.set_ylabel('Power (dB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BandBuilder:\n",
    "    message = \"Band %d - from %.3f hz to %.3f hz\"\n",
    "    \n",
    "    def __init__(self, nyquist_freq = 4096, offset_freq = 0, offset_log = 14, base = 1.415):\n",
    "        # offset frequency because logarithm derivative is low at the start\n",
    "        self.offset_freq = offset_freq\n",
    "        \n",
    "        # offset logarithm\n",
    "        self.offset_log = offset_log\n",
    "        \n",
    "        # logarithm base\n",
    "        self.base = base\n",
    "        \n",
    "        # band count\n",
    "        self.size = self.get_count(nyquist_freq)\n",
    "        \n",
    "        # offset value\n",
    "        self.offset_value = self.offset_freq + self.base ** self.offset_log\n",
    "        \n",
    "        # store band' frequency coverage\n",
    "        self.bands = [ self.offset_freq + self.base ** (x + self.offset_log) for x in range(self.size + 1) ]\n",
    "        \n",
    "    def get_count(self, nyquist_freq):\n",
    "        remaining_freq = nyquist_freq - self.offset_freq\n",
    "        \n",
    "        return math.ceil(math.log(remaining_freq, self.base)) - self.offset_log\n",
    "        \n",
    "        \n",
    "    def show(self):\n",
    "        prov = 0\n",
    "        \n",
    "        for index, band in enumerate(self.bands):\n",
    "            print(self.message % (index, prov, band))\n",
    "            \n",
    "            prov = band\n",
    "        \n",
    "    def get_band(self, value):\n",
    "        if value > self.offset_value:\n",
    "            return math.ceil(math.log(value, self.base) - self.offset_log)\n",
    "        else: return 0\n",
    "        \n",
    "    def get_band_value(self, value):\n",
    "        return self.base ** (self.offset_log + value) + self.offset_freq\n",
    "        \n",
    "# Band class with index within the logarithmic bands and its maximum amplitude\n",
    "class Band:\n",
    "    def __init__(self, index, mag):\n",
    "        self.index = index\n",
    "        self.mag = mag\n",
    "                \n",
    "# band_builder = BandBuilder(2048, 0, offset_log = 16, base = 1.285)\n",
    "# band_builder.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxBands:\n",
    "    def __init__(self, data, band_builder):\n",
    "        # dft data \n",
    "        self.data = data\n",
    "        \n",
    "        # band builder\n",
    "        self.band_builder = band_builder\n",
    "        \n",
    "    # we compute the strongest bins for the bands\n",
    "    def get_bands(self):\n",
    "        result = np.zeros(self.data.shape[0] * self.band_builder.size).reshape(self.data.shape[0], -1)\n",
    "\n",
    "        for band, sample in enumerate(self.data):\n",
    "            for index, value in enumerate(sample):\n",
    "                current_band = self.band_builder.get_band(int(index * 2049 / 102))\n",
    "\n",
    "                if(current_band < self.band_builder.size):\n",
    "                    result[band][current_band] = max(result[band][current_band], value)\n",
    "                    \n",
    "        \n",
    "        return result\n",
    "\n",
    "    def show_band(self, index):\n",
    "        max_bands = self.get_bands()\n",
    "        \n",
    "        values = max_bands[index]\n",
    "        for index, mag in enumerate(values):\n",
    "            print(\"Band %d with val: %d\" % (self.band_builder.get_band_value(index), mag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Band 55 with val: 52\n",
      "Band 71 with val: 56\n",
      "Band 91 with val: 56\n",
      "Band 117 with val: 54\n",
      "Band 150 with val: 63\n",
      "Band 193 with val: 66\n",
      "Band 248 with val: 63\n",
      "Band 319 with val: 52\n",
      "Band 410 with val: 51\n",
      "Band 527 with val: 50\n",
      "Band 678 with val: 39\n",
      "Band 871 with val: 39\n",
      "Band 1120 with val: 31\n",
      "Band 1439 with val: 30\n",
      "Band 1849 with val: 28\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\"dataset\\\\xx\"):\n",
    "    if(file.startswith(\"104 Islands\")):\n",
    "        data, bins = read_audio_source(file)\n",
    "        \n",
    "        band_builder = BandBuilder(2048, 0, offset_log = 16, base = 1.285)\n",
    "        max_bands = MaxBands(data, band_builder)\n",
    "        mag_bands = max_bands.show_band(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roughly approximation for a letter in time domain\n",
    "spacing_letter = 20\n",
    "\n",
    "# same for blank\n",
    "spacing_blank = 40\n",
    "\n",
    "time = [60, 1]\n",
    "def timestr_to_ms(input):\n",
    "    values = input.split(\":\")\n",
    "    \n",
    "    return sum([ int(value) * time[index] for index, value in enumerate(values) ])\n",
    "\n",
    "def interval_to_timestamp(input):\n",
    "    start = timestr_to_ms(input['s'])\n",
    "    end = timestr_to_ms(input['e'])\n",
    "    return (start, end, (end - start) * 1000)\n",
    "\n",
    "def find_occurrences(s, ch):\n",
    "    return len([i for i, letter in enumerate(s) if letter == ch])\n",
    "\n",
    "def get_spacing(is_space, spacing_time):\n",
    "    if(is_space):\n",
    "        return spacing_time * 2\n",
    "    \n",
    "    return spacing_time\n",
    "\n",
    "def string_to_letters(input, data):\n",
    "    lyrics = input[\"d\"]\n",
    "    \n",
    "    start, end, time = interval_to_timestamp(input)\n",
    "\n",
    "    blanks = find_occurrences(lyrics, \" \")\n",
    "    spacing_lyrics = blanks * spacing_blank + (len(lyrics) - blanks) * spacing_letter\n",
    "    spacing_time = time // spacing_lyrics\n",
    "\n",
    "    it = int(start * spacing_letter)\n",
    "    for letter in lyrics:\n",
    "        is_space = letter == \" \"\n",
    "        for i in range(get_spacing(is_space, spacing_time)):\n",
    "            if(is_space):\n",
    "                data[it] = 0\n",
    "            else: data[it] = ord(letter) - 96\n",
    "            \n",
    "            it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = pd.read_json(\"dataset\\\\lyrics.json\", typ = \"series\", orient = \"records\")\n",
    "\n",
    "def get_train_data():\n",
    "    band_builder = BandBuilder(2048, 0, offset_log = 16, base = 1.285)\n",
    "    \n",
    "    input_x = []\n",
    "    input_y = []\n",
    "    \n",
    "    for track in lyrics:\n",
    "        track_name = track[\"track\"]\n",
    "        \n",
    "        data, bins = read_audio_source(track_name + \".mp3\")\n",
    "        \n",
    "        input_x.append(np.array(data, dtype = np.float32))\n",
    "        \n",
    "        data = np.zeros(data.shape[0])\n",
    "        \n",
    "        track_data = track[\"data\"]\n",
    "        for data_stamp in track_data:\n",
    "            string_to_letters(data_stamp, data)\n",
    "            \n",
    "        if(max(data) > 27 or min(data) < 0):\n",
    "            raise ValueError(\"Inconsistent data, contains characters exceeding the alphabet range and space - {}\".format(track_name))\n",
    "            \n",
    "        input_y.append(np.array(data, dtype = np.float32))\n",
    "        \n",
    "    return (np.concatenate(input_x), np.concatenate(input_y))\n",
    "            \n",
    "features, targets = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(features)\n",
    "\n",
    "batch_size_t = 250\n",
    "batch_count = size // batch_size_t \n",
    "\n",
    "remaining_samples = batch_count * batch_size_t\n",
    "\n",
    "test_threshold = batch_count // 9\n",
    "train_threshold = batch_count\n",
    "\n",
    "test_threshold *= batch_size_t\n",
    "train_threshold *= batch_size_t\n",
    "\n",
    "train_features, train_targets = features[test_threshold:train_threshold], targets[test_threshold:train_threshold]\n",
    "test_features, test_targets = features[:test_threshold], targets[:test_threshold]\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_features), torch.from_numpy(train_targets))\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(test_features), torch.from_numpy(test_targets))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size_t, shuffle = False, num_workers = 4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size_t, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.rnn = nn.RNN(102, 102, 10, batch_first = True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(102, 64)\n",
    "        self.fc2 = nn.Linear(64, 27)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.2)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        r_out, hidden = self.rnn(x.view(250, 1, -1), hidden)\n",
    "        \n",
    "        # sequence of fully connected layers\n",
    "        x = self.dropout(F.relu(self.fc1(r_out)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        \n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        \n",
    "        return x, hidden\n",
    "\n",
    "# our model\n",
    "model = Network()\n",
    "\n",
    "# loss function\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.ASGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[21.1642, 19.4310, 16.6414,  ..., 12.8446, 15.0882, 16.6814],\n",
      "        [ 7.7803, 17.5203, 16.0376,  ...,  0.6444,  2.5227,  3.8125],\n",
      "        [ 0.6138, 17.9408, 15.8512,  ...,  1.2929,  1.4347,  1.1877],\n",
      "        ...,\n",
      "        [23.3617, 20.9617, 14.3793,  ...,  6.3720, 12.0207, 14.2314],\n",
      "        [23.8510, 21.5161, 15.1305,  ..., 25.2471, 23.5832, 16.5847],\n",
      "        [11.6736, 15.2833, 13.1877,  ..., 12.6762, 15.5316, 15.2009]])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "features, targets = next(iter(test_loader))\n",
    "\n",
    "output, hidden = model(features, None)\n",
    "\n",
    "loss = criterion(output.view(250, -1), targets.type(dtype = torch.LongTensor))\n",
    "# we have to get 27 class probabilities\n",
    "print(targets)\n",
    "print(features)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (inf --> 0.000000).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.000000 \tValidation Loss: 0.000000\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# number of epochs for model' training\n",
    "epochs_count = 10\n",
    "\n",
    "test_loss_min = np.Inf\n",
    "\n",
    "for epoch in range(1, epochs_count + 1):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    hidden_train = None\n",
    "    hidden_test = None\n",
    "    \n",
    "    model.train()\n",
    "    for features, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # forward pass\n",
    "        output, hidden_train = model(features, hidden_train)\n",
    "        \n",
    "        hidden_train = hidden_train.data\n",
    "        \n",
    "        loss = criterion(output.view(250, -1), targets.type(dtype = torch.LongTensor))\n",
    "        \n",
    "        # backwards pass\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # update training loss\n",
    "        train_loss += loss.item() * features.size(0)\n",
    "        \n",
    "    hidden_test = None\n",
    "\n",
    "    model.eval()\n",
    "    for features, targets in test_loader:\n",
    "        # forward pass\n",
    "        output, hidden_test = model(features, hidden_test)\n",
    "        \n",
    "        hidden_test = hidden_test.data\n",
    "        \n",
    "        # calculate batch loss\n",
    "        loss = criterion(output.view(250, -1), targets.type(dtype = torch.LongTensor))\n",
    "        \n",
    "        # update validation loss \n",
    "        test_loss += loss.item() * features.size(0)\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "        \n",
    "    # print training/validation statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, test_loss))\n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if test_loss <= test_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        test_loss_min,\n",
    "        test_loss))\n",
    "        \n",
    "        torch.save(model.state_dict(), 'lyrics.pt')\n",
    "        test_loss_min = test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-c834921e7546>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, frames, num_frames, exception_on_underflow)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         pa.write_stream(self._stream, frames, num_frames,\n\u001b[1;32m--> 586\u001b[1;33m                         exception_on_underflow)\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'Tensor'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
